#同步和排序约束

虽然不能配置原子数据类型的原子性，但可以调整原子操作的同步和排序约束。这在C#或Java的内存模型中是不可能的，只有在C++中可行。

C++中有六种不同的内存模型。那这些内存模型分别是什么呢?

## C++中六种内存序

我们已经知道C++有六种不同的内存序。原子操作默认的内存序是`std::memory_order_seq_cst`，这表示顺序的一致性。此外，也可以显式地指定其他五个中的一个。那么剩余几个是什么呢?

C++中定义的内存序

```c++
enum memory_order{
  memory_order_relaxed,
  memory_order_consume,
  memory_order_acquire,
  memory_order_release,
  memory_order_acq_rel,
  memory_order_seq_cst
}
```

要对这六种内存序进行分类，需要回答两个问题:

1. 不同的原子操作应该使用哪种内存模型?
2. 6个内存序定义了哪些同步和排序约束?

My plan is quite simple: I answer both questions.

我的计划很简单 —— 回答这两个问题。

## 原子操作的种类

这里有三种不同类型的原子操作：

* *读*(read)操作: `memory_order_acquire`和`memory_order_consume`
* *写*(write)操作: `memory_order_release`
* *读改写*(read-modify-write)操作: `memory_order_acq_rel`和`memory_order_seq_cst`

`memory_order_relaxed`无同步和排序约束，所以它不适用于这种分类方式。

下表根据原子操作的读写特性对它们进行排序。

|        操作名称         | read | write | read-modify-write |
| :---------------------: | :--: | :---: | :---------------: |
|      test_and_set       |      |       |        yes        |
|          clear          |      |  yes  |                   |
|      is_lock_free       | yes  |       |                   |
|          load           | yes  |       |                   |
|          store          |      |  yes  |                   |
|        exchange         |      |       |        yes        |
| compare_exchange_strong |      |       |        yes        |
|  compare_exchange_weak  |      |       |                   |
|      fetch_add, +=      |      |       |        yes        |
|      fetch_sub, -=      |      |       |                   |
|      fetch_or, \|=      |      |       |        yes        |
|      fetch_and, &=      |      |       |                   |
|      fetch_xor, ^=      |      |       |                   |
|         ++, --          |      |       |        yes        |

“读改写”操作还有一个额外的保证：总是提供最新的值。这意味着，不同线程上的`atomVar.fetch_sub(1)`操作序列一个接一个地计数，无缝衔接或进行重复。

如果将原子操作`atomVar.load()`与“写”或“读改写”操作一起使用，那么“写”的部分将不起作用。结果就是：`atomVar.load(std::memory_order_acq_rel)`等价于`atomVar.load(std::memory_order_acquire)`，`atomVar.load(std::memory_order_release)`等价于`atomVar.load(std::memory_order_relax)`。

## 同步与排序约束的不同

大致说来，C++中有三种不同类型的同步和排序约束:

* 顺序一致性: `memory_order_seq_cst`
* 获取-释放(Acquire-release)：`memory_order_consume` , `memory_order_acquire` ,` memory_order_release`和`memory_order_acq_rel`
* 自由序(Relaxed): `memory_order_relaxed`

顺序一致性在线程之间建立全局顺序，而获取-释放语义为不同线程之间，对同一原子变量进行读写操作时建立顺序。自由语序只保证了原子变量的修改顺序，修改顺序是指对一个特定原子变量的所有修改都以某种特定的顺序发生。因此，由特定线程读取原子对象时，不会看到比线程已经观察到的值“更旧”的值。

不同的内存模型，及其对原子和非原子操作的影响，使建立C++内存模型有趣但又具有挑战性。下面我们来讨论顺序一致性、获得-释放语义和自由语义的同步和排序约束。

### 顺序一致性

让我们深入地研究一下顺序一致性，其关键是所有线程上的所有操作都遵从一个通用时钟。这个全球时钟让我们可以很直观的想象它的存在。

顺序一致性的直观性是有代价的，缺点是系统必须对线程进行同步。

下面的程序在顺序一致性的帮助下，同步生产者和消费者线程。

```c++
// producerConsumer.cpp

#include <atomic>
#include <iostream>
#include <string>
#include <thread>

std::string work;
std::atomic<bool> ready(false);

void consumer(){
  while(!ready.load()){}
  std::cout << work << std::endl;
}

void producer(){
  work = "done";
  ready = true;
}

int main(){
  std::thread prod(producer);
  std::thread con(consumer);
  prod.join();
  con.join();
}
```

这个程序的输出：

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/9.png)

由于顺序一致性，程序执行结果是确定的，所以总是输出“done”。

The graphic depicts the sequence of operations. The consumer thread waits in the while-loop until the atomic variable ready is set to true . When this happens, the consumer threads continues its work.

下图描述了操作的顺序。消费者线程在`while`循环中等待，直到原子变量`ready`被生产者线程设置为`true`。当这种情况发生时，消费者线程将继续其工作。

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/10.png)

理解程序总是返回“done”并不困难，只需要使用顺序一致性的两个特性：一方面，两个线程以源代码的顺序执行指令；另一方面，每个线程以相同的顺序查看另一个线程的操作。两个线程遵循相同的时钟。在`while(!ready.load()){}`循环中，这种同步也可以保持下去——用于同步生产者线程和消费者线程。

通过使用内存序，可以更正式地解释这个过程。以下是正式版本:

1. `work= "done"` 在序列中，位于 `ready = true`之前
   ⇒ `work= "done"` 先行与 `ready = true`
2. `while(!ready.load()){}`序列位位于 `std::cout << work << std::endl`之前
   ⇒ `while(!ready.load()){}`先行与`std::cout<< work << std::endl`
3. `ready= true`与`while(!ready.load()){}`同步
   ⇒ `ready= true`(线程间)先行于 `while (!ready.load()){}`
   ⇒ `ready= true`先行于`while (!ready.load()){}`

最终的结论：因为先行关系是可以传递的，所以`work = "done"`先行于`ready= true`，且先行于`while(!ready.load()){}`，更先行于`std::cout<< work << std::endl`。

顺序一致性中，一个线程可以看到另一个线程的操作，因此也可以看到所有其他线程的操作。如果使用原子操作的获取-释放语义，那么顺序一致性就不成立了。这是与C#和Java不同的地方，也是我们开始产生疑惑的地方。

### 获取-释放 语义

获取-释放语义中，线程间不存在全局同步：只有同一原子变量上的原子操作之间才进行同步。比如：一个线程上的写操作与另一个线程上的读操作，只有作用于同一个原子变量时才进行同步。

获取-释放语义的基本思想：释放操作与获取操作在同一原子上同步，并建立一个顺序约束。这意味着，在释放操作之后不能进行所有的读写操作，在获取操作之前不能进行所有的读写操作。

什么是获取/释放操作？使用`load`或`test_and_set`读取原子变量是一个获取操作。还有，锁或互斥锁的释放与获取是同步的，线程的构造与调用间是同步的，线程的完成与汇入调用间的操作是同步的，任务可调用的完成与等待或获取future的调用操作是同步的。所以，获取和释放操作是成对的。

下面这张图有利于对 获取-释放语义的理解：

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/11.png)

> 贴士
>
> **内存模型——更深入地理解多线程**
>
> 这应该是要了解内存模型的主要原因。特别是，获取-释放语义也可以帮助您更好地理解高级同步原语，比如互斥锁。同样的原理也适用于线程的启动和线程的汇入。这两种操作都是获取-释放操作。接下来是`wait`和`notify_one`对条件变量的调用；`wait`是获取操作，`notify_one`是释放操作。那`notify_all`呢？当然，也是一个释放操作。

现在，我们再看`std::atomic_flag`小节中的自旋锁。因为同步是使用`atomic_flag flag`完成的，所以我们可以实现的更高效它，用的就是“获取-释放语义”。

```c++
// spinlockAcquireRelease.cpp

#include <atomic>
#include <thread>

class Spinlock{
  std::atomic_flag flag;
public:
  Spinlock():flag(ATOMIC_FLAG_INIT){}
  
  void lock(){
    while(flag.test_and_set(std::memory_order_acquire));
  }
  
  void unlock(){
    flag.clear(std::memory_order_release);
  }
};

Spinlock spin;

void workOnResource(){
	spin.lock();
  // shared resource
  spin.unlock();
}

int main(){
  
  std::thread t(workOnResource);
  std::thread t2(workOnResource);
  
  t.join();
  t2.join();
}
```

第16行` flag.clear `是清除标志，`test_and_set`在第12行调用一个获取操作，获取操作与释放操作同步。具有顺序一致性的两个线程的同步(重同步)(`std::memory_order_seq_cst`)被更轻量级的和性能更强的获取-释放语义(`std::memory_order_acquire`和`std::memory_order_release`)所取代，且程序行为不受影响。

虽然`flag.test_and_set(std::memory_order_acquire)`调用是一个"读改写"操作，但是获取语义已经足够了。总之，`flag`是原子的，因此可以保证其修改顺序。这也就意味着，对`flag`的所有修改都以某种特定的顺序进行。

获得-释放语义是可传递的。这意味着，如果两个线程(a,b)之间遵循获取-释放语义，且线程(b,c)之间也遵循获取-释放语义，那么在线程(a, c)之间则也遵循获取-释放语义。

#### 传递性

释放与获取操作在同一个原子变量上同步，并建立排序约束。如果它们作用于相同的原子变量，这些组件将以最高效的方式同步线程。如果两个线程没有共享的原子变量，会如何工作呢？我们不想使用顺序一致性，因为代价过高，我们想要更轻量级的获取-释放语义。

解决方式很简单，就是利用获取-释放语义的传递性，我们可以同步的独立线程。

下面的示例中，线程t2及其工作包`deliveryBoy`是两个独立线程t1和t3之间的连接线程。

```c++
// transitivity.cpp

#include <atomic>
#include <iostream>
#include <thread>
#include <vector>

std::vector<int> mySharedWork;
std::atomic<bool> dataProduced(false);
std::atomic<bool> dataConsumed(false);

void dataProducer(){
  mySharedWork = {1,0,3};
  dataProduced.store(true, std::memory_order_release);
}

void deliverBoy(){
  while(!dataProduced.load(std::memory_order_acquire));
  dataConsumed.store(true, std::memory_order_release);
}

void dataConsumer(){
  while(!dataConsumed.load(std::memory_order_acquire));
  mySharedWork[1] = 2;
}

int main(){
  std::cout << std::endl;
  
  std::thread t1(dataConsumer);
  std::thread t2(deliverBoy);
  std::thread t3(dataProducer);
  
  t1.join();
  t2.join();
  t3.join();
  
  for (auto v : mySharedWork){
    std::cout << v << " ";
  }
  
  std::cout << "\n\n";
  
}
```

程序的输出是唯一的，`mySharedWork`的值为`1, 2, 3`。

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/12.png)

通过观察，得出两个结论：

1. 线程t2在第18行等待，直到线程t3将`dataProduced`设置为`true`(第14行)。
2. 线程t1在第23行等待，直到线程t2将`dataConsumed`设置为`true`(第19行)。

用图表来解下：

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/13.png)

图中主要部分是箭头。

* 蓝色箭头是顺序关系，线程中的所有操作都是按源码顺序执行的。
* 红色的箭头是同步关系。原因是对同一原子变量的原子操作遵循的获取-释放语义。原子变量之间，以及线程同步发生在特定的点上。
* 顺序关系建立了先行关系，再使用线程间的先行关系建立了同步关系。

剩下的部分就好理解了，线程间的先行指令的顺序对应于从上到下箭头的方向。最后，能够保证执行`mySharedWork[1] == 2`。

释放-获取操作是同步的(同一个原子变量)，所以可以很容易地同步线程，不过…… 我们还要来了解几个误解。

#### 典型的误解

写关于获取-释放语义误解的动机是什么?我的许多读者和学生已经发现了这些陷阱。让我们来看一个简单的例子。

##### 等待

以一个简单的程序作为基点。

```c++
// acquireReleaseWithWaiting.cpp

#include <atomic>
#include <iostream>
#include <thread>
#include <vector>

std::vector<int> mySharedWork;
std::atomic<bool> dataProduced(false);

void dataProducer(){
  mySharedWork = {1,0,3};
  dataProduced.store(true, std::memory_order_release);
}

void dataConsumer(){
  while(!dataProduced.load(std::memory_order_acquire));
  mySharedWork[1] = 2;
}

int main(){
  
  std::cout << std::endl;
  
  std::thread t1(dataConsumer);
  std::thread t2(dataProducer);
  
  t1.join();
  t2.join();
  
  for (auto v: mySharedWork){
    std::cout << v << " ";
  }
    
  std::cout << "\n\n";
  
}
```

第17行的消费者线程t1持续等待，直到第13行的消费者线程t2将数据设置为`true`。`dataProduced`是一个保护，它保证对非原子变量`mySharedWork`的访问是同步的。这意味着生产者线程t2初始化`mySharedWork`，然后消费者线程t2通过设置`mySharedWork[1]`为2来完成工作。程序没有问题。

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/14.png)

下图显示了线程中的先行关系和线程之间的同步关系。同步在线程间建立了先行关系，其余顺序可以根据先行关系的传递性推理得出。

最后，让`mySharedWork = {1, 0, 3} `先行于`mySharedWork[1] = 2 `。

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/15.png)

有没有感觉这个推理过程中经常缺少什么？如果……

##### 如果……

如果第17行中的消费者线程t1没有等待生产者线程t2，会发生什么?

```c++
// acquireReleaseWithoutWaiting.cpp

#include <atomic>
#include <iostream>
#include <thread>
#include <vector>

std::vector<int> mySharedWork;
std::atomic<bool> dataProduced(false);

void dataProducer(){
  mySharedWork = {1,0,3};
  dataProduced.store(true, std::memory_order_release);
}

void dataConsumer(){
 	dataProduced.load(std::memory_order_acquire);
  myShraedWork[1] = 2;
}

int main(){
  
  std::cout << std::endl;
  
  std::thread t1(dataConsumer);
  std::thread t2(dataProducer);
  
  t1.join();
  t2.join();
  
  for (auto v : mySharedWork){
    std::cout << v << " ";
  }
  
  std::cout << "\n\n";
  
}
```

因为变量`mySharedWork`上存在数据竞争，所以该程序具有未定义的行为。当程序运行时，将得到以下结果。

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/16.png)

问题在哪里呢？这里`dataProduced.store(true, std::memory_order_release)`与`dataProduced.load(std::memory_order_acquire)`同步。不过，并不意味着获取操作要对释操作进行等待，而这正是下图中的内容。图中，`dataProduced.load(std::memory_order_acquire)`在指令`dataProduced.store(true, std::memory_order_release)`。所以这里没有同步关系。

![](../../../images/detail/memory-model/17.png)

#### 解决办法

同步意味着：当`dataProduced.store(true, std::memory_order_release) `先行于`dataProduced.load(std::memory_order_acquire)`，那么`dataProduced.store(true, std::memory_order_release)`之前和`dataProduced.load(std::memory_order_acquire)`之后执行的操作是所有线程可见的。第一个程序中使用`while(! dataproduct .load(std::memory_order_acquire))`来保证同步关系。

再描述一次，使用正式的方式。

当满足条件：`dataProduced.store(true, std::memory_order_release)`先行于`dataProduced.load(std::memory_order_acquire) `时，`dataProduced.store(true, std::memory_order_release)`之前执行的操作先行于所有`dataProduced.load(std::memory_order_acquire)`之后执行的操作。

#### 释放顺序

处理获取-释放语义时，释放顺序是一个相当高级的概念。因此，我们首先从以下示例中的获取-释放语义开始说起。

```c++
// releaseSequence.cpp

#include <atomic>
#include <thread>
#include <iostream>
#include <mutex>

std::atomic<int> atom{0};
int somethingShared{0};

using namespace std::chrono_literals;

void writeShared(){
  somethingShared = 2011;
  atom.store(2, std::memory_order_release);
}

void readShared(){
  while(!(atom.fetch_sub(1, std::memory_order_acquire) > 0)){
    std::this_thread::sleep_for(100ms);
  }
  std::cout << "somethingShared: " << somethingShared << std::endl;
}

int main(){
  
  std::cout << std::endl;
  
  std::thread t1(writeShared);
  std::thread t2(readShared);
  // std::thread t3(readShared);
  
  t1.join();
  t2.join();
  // t3.join();
  
  std::cout << "atom: " << atom << std::endl;
  
  std::cout << std::endl;
  
}
```

让我们先看看没有线程t3的例子。第15行对原子进行存储操作，第19行对原子获取并同步线程。这里对非原子变量`somethingShared`的访问不存在数据竞争。

如果打开t3线程的注释，会发生什么变化？现在可能会出现了一场“数据竞争”。如前所述，`atom.fetch_sub(1, std::memory_order_acquire) `(第19行)与` atom.store(2, std::memory_order_release)`(第15行)让`atom`遵循获取-释放语序；因此，在`somethingShared `变量的访问上没有数据竞争。

但对于第二次调用`atom.fetch_sub(1, std::memory_order_acquire)`，获取-释放语序则不起作用了。第二次调用则是一个读改写操作，因为已经没有在对`std::memory_order_release`进行标记了。这也就意味着第二次调用与第一次调用并没有同步关系，所以可能会发生对共享变量的数据竞争。也许，释放顺序可能不会让数据竞争发生。这里，释放序列扩展到对`atom.fetch_sub(1, std::memory_order_acquire) `的第二次调用；因此，第二次调用`atom.fetch_sub(1, std::memory_order_acquire)`先行于第一次调用。

最终，我们可能会得到如下的结果：

![](../../../images/detail/memory-model/18.png)

更正式的释放顺序的由N4659定义([N4659: Working Draft, Standard for Programming Language C++]( http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf))。

> 知识点
>
> **释放顺序**
>
> 释放序列顺序由一个释放操作A在一个原子对象M构成，修改M的顺序的副作用是最大连续子操作序列，也就是A的第一次调用，和随后由相同线程执行的的`*`操作，这里`*`指的是对源子的读改写操作。

如果你仔细看了我的解释，比如了解挑战小节中的信息，你可能会期待接下来出现自由语义；不过，我们还是来看下内存模型`std:: memory_order_consumption`，它与`std::memory_order_acquire`非常相似

#### std::memory_order_consume

`std::memory_order_consume `是六种内存序中最传奇的一个。这有二：一，`std:: memory_order_consumption`非常难理解；二，因为目前没有编译器支持它，所以这个内存序可能在未来会进行修改。C++17中情况会更糟。官方的说法是：“释放-消费序的规范正在修改，暂不推荐使用`memory_order_consumption`。”

为什么支持C++ 11标准的编译器，不支持`std:: memory_order_consumption`呢？答案是，编译器会将`std:: memory_order_consumption`映射为`std::memory_order_acquire`。这没毛病，因为两者都是加载或获取操作。`std::memory_order_consume`比`std::memory_order_acquire`需要的同步和排序约束更弱。因此，释放-获排序可能比释放-消费序慢，但是关键点是该内存序有良好的定义。

将释放-消费序与释放-获取排序进行比较，可以更好的对其进行了解。下一小节中，将讨论释放-获取语序，以了解`std::memory_order_consume`和`std::memory_order_acquire`之间的紧密关系。

#### 释放-获取序

首先，让我们使用下面的程序和两个线程`t1`和`t2`。`t1`扮演生产者的角色，`t2`扮演消费者的角色。原子变量`ptr`用于同步生产者和消费者。

```c++
// acquireRelease.cpp

#include <atomic>
#include <thread>
#include <iostream>
#include <string>

using namespace std;

atomic<string*> ptr;
int data;
atomic<int> atoData;

void producer(){
  string *p = new string("C++11");
  data = 2011;
  atoData.store(2014, memory_order_relaxed);
  ptr.store(p, memory_order_release);
}

void consumer(){
  string *p2;
  while(!(p2 = ptr.load(memory_order_acquire)));
  cout << "*p2: " << *p2 << endl;
  cout << "data: " << data << endl;
  cout << "atoData: " << atoData.load(memory_order_relaxed) << endl;
}

int main(){
  
  cout << endl;
  
  thread t1(producer);
  thread t2(consumer);
  
  t1.join();
  t2.join();
  
  cout << endl;
  
}
```

分析程序之前，进行一些变化。

#### 释放-消费序

将第21行中的内存顺序`std::memory_order_acquire`替换为`std:: memory_order_consumption`。

```c++
// acquireConsume.cpp

#include <atomic>
#include <thread>
#include <iostream>
#include <string>

using namespace std;

atomic<string*> ptr;
int data;
atomic<int> atoData;

void producer(){
  string *p = new string("C++11");
  data = 2011;
  atoData.store(2014, memory_order_relaxed);
  ptr.store(p, memory_order_release);
}

void consumer(){
  string *p2;
  while(!(p2 = ptr.load(memory_order_acquire)));
  cout << "*p2: " << *p2 << endl;
  cout << "data: " << data << endl;
  cout << "atoData: " << atoData.load(memory_order_relaxed) << endl;
}

int main(){
  
  cout << endl;
  
  thread t1(producer);
  thread t2(consumer);
  
  t1.join();
  t2.join();
  
  cout << endl;
  
}
```

现在程序存在有未定义的行为。不过这种情况只能是一种猜测，因为GCC 5.4编译器使用`std::memory_order_acquire`实现了` std::memory_order_consume` ，所以程序改动前和改动后是相同的。

#### 释放-获取 Vs. 释放-消费

程序输出结果是相同的。

![](../../../images/detail/memory-model/19.png)

解释一下，为什么第一个程序(acquireRelease.cpp)没有问题(定义良好)。

因为存储操作使用`std::memory_order_release`，而加载操作使用`std::memory_order_acquire`，所以第16行上的存储操作与第21行中的加载操作同步。释放-获取序约束是什么呢？释放-获取序确保在存储操作(第16行)前所有操作的结果在加载操作(第21行)之后可用。同样，释放-获取操作对非原子变量(第14行)和原子变量`atoData`(第15行)的访问进行排序。虽然，`atoData`使用`std::memory_order_relax`内存排序，但这是成立的。

关键的问题是：如果用`std::memory_order_consumption`替换`std::memory_order_acquire`会发生什么?

#### std::memory_order_consume的数据依赖

`std::memory_order_consume`需要处理原子上的数据依赖关系，数据依赖性以两种方式存在。首先，让我们看看线程中的携依赖和两个线程之间的依赖关系。两个依赖都引入了一个先行关系。我们正在寻找这种关系。“*携依赖*(carries-a-dependency-to)”和“*先依赖序*(dependency-order-before)”是什么意思？

* 携依赖: 如果操作A的结果在操作B中作为操作数，则：A携依赖于B。
* 先依赖序:存储操作(使用`std::memory_order_release`、`std::memory_order_acq_rel`或`std:: memory_seq_cst`)是按依赖序进行排序的——如果在同一个线程中的后续操作C中加载了操作B的结果，则需要在加载操作B之前使用`std::memory_order_consume`。需要注意的是，操作B和C必须在同一个线程中。

以我的经验，这两个定义不是很好懂。这里有用图可能会更直观一些。

![](../../../images/detail/memory-model/20.png)

`ptr.store(p, std::memory_order_release)`是按先依赖序排列在`while (!(p2 = ptr.load(std::memory_order_consume))) `之前的，因为下行`std::cout << "*p2: " << p2 << std::endl`可看作为加载操作的结果输出。此外，`while (!(p2 = ptr.load(std::memory_order_consume))`携依赖于`cout << "p2: " << *p2 << < std::endl`，因为`*p2`使用了ptr的结果进行输出。

我们无法保证`data `和`atoData`的输出。这是因为两者与`ptr.load`操作没有携依赖关系。更糟糕的是：由于数据是非原子变量，因此存在竞争条件。原因是两个线程可以同时访问数据，并且线程t1要对数据进行修改。因此，程序具有未定义的行为。

最后，我们来了解自由语义。

### 自由语义

The relaxed semantic is the other end of the spectrum. The relaxed semantic is the weakest of all memory models and only guarantees the modification order of atomics. This means all modifications on an atomic occur in some particular total order.

#### 无同步和排序约束

This is quite easy. If there are no rules, we can not violate them. However, that is too easy; the program should have well-defined behaviour. This means in particular that you typically use synchronisation and ordering constraints of stronger memory orderings to control operations with relaxed semantic. How does this work? A thread can see the effects of another thread in arbitrary order, so you have to make sure there are points in your program where all operations on all threads get synchronised.

A typical example of an atomic operation, in which the sequence of operations doesn’t matter, is a counter. The critical observaion for a counter is not in which order the different threads increment the counter; the critical observation for a counter is that all increments are atomic and that all threads’ tasks are done at the end. Have a look at the following example.

A counter with relaxed semantic

```c++

```

The three most exciting lines are 13, 24, and 26.

In line 13 the atomic number count is incremented using the relaxed semantic, so we have a guarantee that the operation is atomic. The fetch_add operation establishes an ordering on count . The function add (lines 10 - 15) is the work package of the threads. Each thread gets its work package on line 21.

Thread creation is one synchronisation point. The other one being t.join() on line 24.

The creator thread synchronises with all its children in line 24. It waits with the t.join() call until all its children are done. t.join() is the reason that the results of the atomic operations are published. To say it more formally: t.join() is a release operation.

In conclusion, there is a happens-before relation between the increment operation in line 13 and the reading of the counter count in line 26.

The result is that the program always returns 10000. Boring? No, it’s reassuring!

![](../../../images/detail/memory-model/21.png)

A typical example of an atomic counter which uses the relaxed semantic is the reference counter of std::shared_ptr . This only holds for the increment operation. The key property for incrementing the reference counter is that the operation is atomic. The order of the increment operations does not matter. This does not hold for the decrement of the reference counter. These operations need an acquire-release semantic for the destructor.

> 知识点
>
> **无等待的累加计算**
>
> Have a closer look at the function add in line 10. There is no synchronisation involved in the increment operation (line 13). The value 1 is just added to the atomic count 
>
> Therefore, the algorithm is not only lock-free but it is also wait-free.

The fundamental idea of std::atomic_thread_fence is to establish synchronisation and ordering constraints between threads without an atomic operation.