#The Synchronisation and Ordering Constraints

You cannot configure the atomicity of an atomic data type, but you can accurately adjust the synchronisation and ordering constraints of atomic operations. This is a possibility which is unique to C++ and is not possible in C#’s or Java’s memory model.

There are six different variants of the memory model in C++. The key question is what their characteristics are?

## The Six Variants of Memory Orderings in C++

We already know C++ has six variants of the memory ordering. The default for atomic operations is std::memory_order_seq_cst . This expression stands for sequential consistency. In addition, you can explicitly specify one of the other five. So what does C++ have to offer?

The memory orderings



To classify these six memory ordering, it helps to answer two questions:

1. Which kind of atomic operations should use which memory model?
2. Which synchronisation and ordering constraints are defined by the six variants?

My plan is quite simple: I answer both questions.

## Kind of Atomic Operation

There are three different kinds of operations:

* Read operation: memory_order_acquire and memory_order_consume
* Write operation: memory_order_release
* Read-modify-write operation: memory_order_acq_rel and memory_order_seq_cst

memory_order_relaxed defines no synchronisation and ordering constraints. It does not fit in this taxonomy.

The following table orders the atomic operations based on their reading and writing characteristics.

Characteristics of Atomic Operations



Read-modify-write operations have an additional guarantee: they always provide the newest value. This means a sequence of atomVar.fetch_sub(1) operations on different threads counts down one after the other without any gaps or duplicates.

If you use an atomic operation atomVar.load() with a memory model that is designed for a
write or read-modify-write operation, the write part has no effect. The result is that operation atomVar.load(std::memory_order_acq_rel) is equivalent to operation atomVar.load(std::memory_order_acquire) ; operation atomVar.load(std::memory_order_release) is equivalent to atomVar.load(std::memory_order_relaxed) 

## Different Synchronisation and Ordering Constraints

There are, roughly speaking, three different types of synchronisation and ordering constraints in C++:

* Sequential consistency: memory_order_seq_cst
* Acquire-release: memory_order_consume , memory_order_acquire , memory_order_release , and memory_order_acq_rel
* Relaxed: memory_order_relaxed

While the sequential consistency establishes a global order between threads, the acquire-release semantic establishes an ordering between reading and writing operations on the same atomic variable with different threads. The relaxed semantic only guarantees the modification order of some atomic m . Modification order means that all modifications on a particular atomic m occur in some particular total order. Consequently, reads of an atomic object by a particular thread never see “older” values than those the thread has already observed.

The different memory models and their effects on atomic and non-atomic operations make the C++ memory model an interesting, but also challenging, topic. Let us discuss the synchronisation and ordering constraints of the sequential consistency, the acquire-release semantic, and the relaxed semantic.

## Sequential Consistency

Let us dive deeper into sequential consistency. The key for sequential consistency is that all operations on all threads obey a universal clock. This global clock makes it quite intuitive to think about it.

The intuitiveness of the sequential consistency comes with a price. The downside is that the system has to synchronise threads.

The following program synchronises the producer and the consumer thread with the help of sequential consistency.

Producer-Consumer synchronisation with sequential consistency



The output of the program is not very exciting.

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/9.png)

Because of sequential consistency, the program execution is deterministic. Its output is always “done”.

The graphic depicts the sequence of operations. The consumer thread waits in the while-loop until the atomic variable ready is set to true . When this happens, the consumer threads continues its work.

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/10.png)

> Execution order of the sequential consistency

It is quite easy to understand that the program always return “done”. We only have to use the two characteristics of sequential consistency. On the one hand, both threads execute their instructions in source code order, on the other hand, each thread sees the operations of the other thread in the same order. Both threads follow the same universal clock. This synchronisation does also hold with the help of the while(!ready.load()){} loop - for the synchronisation of the producer and the consumer thread.

I can explain the reasoning a lot more formally by using the terminology of the memory ordering. Here is the formal version:

1. work= "done" is sequenced-before ready = true
   ⇒ work= "done" happens-before ready = true
2. while(!ready.load()){} is sequenced-before std::cout << work << std::endl
   ⇒ while(!ready.load()){} happens-before std::cout<< work << std::endl
3. ready= true synchronizes-with while(!ready.load()){}
   ⇒ ready= true inter-thread happens-before while (!ready.load()){}
   ⇒ ready= true happens-before while (!ready.load()){}

The final conclusion: because the happens-before relation is transitive, it follows work = "done" happens-before ready= true happens-before while(!ready.load()){} happens-before std::cout<< work << std::endl

In sequential consistency, a thread sees the operations of another thread and therefore of all other threads in the same order. The critical characteristic of sequential consistency does not hold if we use the acquire-release semantic for atomic operations. This is an area where C# and Java does not follow. That’s also an area where our intuition begins to wane.

## Acquire-Release Semantic

There is no global synchronisation between threads in the acquire-release semantic; there is only synchronisation between atomic operations on the same atomic variable. A write operation on one thread synchronises with a read operation on another thread on the same atomic variable.

The acquire-release semantic is based on one fundamental idea: a release operation synchronises with an acquire operation on the same atomic and establishes an ordering constraint. This means all read and write operations cannot be moved after a release operation, and all read and write operations cannot be moved before an acquire operation.

What is an acquire or release operation? The reading of an atomic variable with load or test_and_set is an acquire operation. There is more: There is more: the releasing of a lock or mutex synchronizes-with the acquiring of a lock or a mutex. The construction of a thread synchronizes-with the invocation of the callable. The completion of the thread synchronizes-with the join-call. The completion of the callable of the task synchronizes-with the call to wait or get on the future. Acquire and release operations come in pairs.

It helps a lot to keep that picture in mind.

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/11.png)

> 贴士
>
> **The memory model for a deeper understanding of mul-tithreading**
>
> This is the main reason you should keep the memory model in mind. In particular the acquire-release semantic helps you to get a better understanding of the high-level synchronisation primitives such as a mutex. The same reasoning holds for the starting of a thread and the join-call on a thread. Both are acquire-release operations. The story goes on with the wait and notify_one call on a condition variable; wait is the acquire and notify_one the release operation. What’s about notify_all ? That is a release operation as well.

Now, let us look once more at the spinlock in the subsection std::atomic_flag. We can write it more efficiently because the synchronisation is done with the atomic_flag flag . Therefore the acquire-release semantic applies.

A Spinlock with acquire-release semantic



The flag.clear call in line 16 is a release, the flag.test_and_set call in line 12 an acquire operation, and the acquire synchronises with the release operation. The heavyweight synchronization of two threads with sequential consistency ( std::memory_order_seq_cst ) is replaced by the more lightweight and performant acquire-release semantic ( std::memory_order_acquire and std::memory_order_release ). The behaviour is not affected.

Although the flag.test_and_set(std::memory_order_acquire) call is a read-modify-write operation, the acquire semantic is sufficient. In summary, flag is an atomic and guarantees, therefore, modification order. This means all modifications to flag occur in some particular total order.

The acquire-release semantic is transitive. That means if you have an acquire-release semantic between two threads(a,b) and an acquire-release semantic between(b,c), you get an acquire-release semantic between (a, c).

## Transitivity

A release operation synchronises with an acquire operation on the same atomic variable and, additionally, establishes ordering constraint. These are the components to synchronise threads in a performant way if they act on the same atomic. How can that work if two threads share no atomic variable? We do not want any sequential consistency because that is too expensive, but we want the light-weight acquire-release semantic.

The answer to this question is straightforward. Applying the transitivity of the acquire-release semantic, we can synchronise threads that are independent.

In the following example, thread t2 with its work package deliveryBoy is the connection between two independent threads t1 and t3 

Transitivity of the acquire-release semantics



The output of the program is deterministic. mySharedWork has the values 1,2 and 3.

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/12.png)

There are two important observations:

1. Thread t2 waits in line 18, until thread t3 sets dataProduced to true (line 14).
2.  Thread t1 waits in line 23, until thread t2 sets dataConsumed to true (line 19).

Let me explain the rest with a graphic.

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/13.png)

> Transitivity of the acquire-release semantic

The essential parts of the picture are the arrows.

* The blue arrows are the sequenced-before relations. This means that all operations in one thread are executed in source code order.
* The red arrows are the synchronizes-with relations. The reason is the acquire-release semantic of the atomic operations on the same atomic. The synchronisation between the atomics, and therefore between the threads happen at specific points.
* sequenced-before establishes a happens-before and synchronizes-with a inter-thread happens-before relation.

The rest is pretty simple. The happens-before and inter-thread happens-before order of the instructions corresponds to the direction of the arrows from top to bottom. Finally, we have the guarantee that mySharedWork[1] == 2 is executed last.

A release operation synchronizes-with an acquire operation on the same atomic variable, so we can easily synchronise threads, if … . The typical misunderstanding is about the if.

## The Typical Misunderstanding

What is my motivation for writing about the typical misunderstanding of the acquire-release semantic? Many of my readers and students have already fallen into this trap. Let’s look at the straightforward case.

### Waiting Included

Here is a simple program as a starting point.

Acquire-release with waiting

```c++

```

The consumer thread t1 in line 17 waits until the consumer thread t2 in line 13 sets dataProduced to true . dataProduced is the guard and it guarantees that access to the non-atomic variable mySharedWork is synchronised. This means that the producer thread t2 initialises mySharedWork then the consumer thread t2 finishes the work by setting mySharedWork[1] to 2 . The program is well-defined.

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/14.png)

The graphic shows the happens -before relation with in the threads and the synchronizes-with relation between the threads. synchronizes-with establishes an inter-thread happens-before relation. The rest of the reasoning is the transitivity of the happens-before relation.

Finally it holds that mySharedWork = {1, 0, 3} happens-before mySharedWork[1] = 2 

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/15.png)

What aspect is often missing in this reasoning? The if.

### If …

What happens if the consumer thread t1 in line 17 doesn’t wait for the producer thread t2 ?

Acquire-release without waiting

```c++

```

The program has undefined behaviour because there is a data race on the variable mySharedWork . When we let the program run, we get the following non-deterministic behaviour.

![](E:/openSourceProjecrts/gitbook/Concurrency-with-Modern-C++/images/detail/memory-model/16.png)

What is the issue? It holds that dataProduced.store(true, std::memory_order_release) synchronizes-with dataProduced.load(std::memory_order_acquire) . But that doesn’t mean the acquire operation waits for the release operation, and that is exactly what is displayed in the graphic. In the graphic the dataProduced.load(std::memory_order_acquire) instruction is performed before the instruction dataProduced.store(true, std::memory_order_release) . We have no synchronizes-with relation.

![](../../../images/detail/memory-model/17.png)