# 关于执行

executor是C++中执行的基本构造块，在执行中扮演如同容器分配器的角色。异步、标准模板库的并行算法、future的协同、任务块的运行、[网络TS(技术规范，technical specification)](https://en.cppreference.com/w/cpp/experimental)的提交、调度或延迟调用等功能都会使用到异步执行。此外，因为没有标准化的执行方式，所以“执行”是编程的基本关注点。

下面是提案[P0761](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0761r2.pdf)的示例。

parallel_for的实现

```c++
void parallel_for(int facility, int n, function<void(int)> f) {
	if(facility == OPENMP) {
		#pragma omp parallel for
		for(int i = 0; i < n; ++i) {
			f(i);
		}
	}
	else if(facility == GPU) {
		parallel_for_gpu_kernel<<<n>>>(f);
	}
	else if(facility == THREAD_POOL) {
		global_thread_pool_variable.submit(n, f);
	}
}
```

这个parallel_for实现有一些问题：

* parallel_for这样看起来简单的函数，但维护起来其实非常复杂。如果支持新的算法或新的并行范例，会变得越来越复杂。(译者：这里指的是分支中不同平台的实现，如果有新算法或新平台，则函数体会变得越来越臃肿。)
* 函数的每个分支的同步属性也不同。OpenMP可能会阻塞运行，直到所有的派生线程完成，GPU通常异步运行的，线程池可能阻塞或不阻塞。不完全的同步可能会导致数据竞争或死锁。
* parallel_for的限制太多。例如，没有办法使用自定义的线程池替换全局线程池:`global_thread_pool_variable.submit(n, f); `

## 路漫漫其修远兮

2018年10月，已经提交了很多关于executor的提案了，许多设计决策非常开放，真的期望它们能成为C++23的一部分，或有可能用C++20对单向执行进行标准化。本章主要是基于对executor的[P0761号提案](](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0761r2.pdf))的设计建议，和在[P0443](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0443r7.html)和[P1244](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1244r0.html)提案中的描述进行的。P0443(统一的executor)中提出了单向执行，它可能是C++20的一部分，P1244(统一的executor的从属执行)提出了从属执行，它可能是C++23的一部分。本章还提到了相对较新的[P1055](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1055r0.pdf)提案，“适当executor提案”。

## Executor是个啥?

首先。什么是executor?executor由一组关于在何处、何时以及如何运行可调用单元的规则组成。

*  何处: 可调用项可以在内部或外部处理器上运行，并且结果是从内部或外部处理器中进行读取。
* 何时: 可调用项可以立即运行，也可以延迟运行。
* 如何: 可调用项的可以在CPU或GPU上运行，甚至可以以向量化的方式执行。

更正式地说，每个executor都具有与所执行函数相关联的属性。

**Executor属性**

可以通过两种方式，将这些属性与executor关联起来:`execution::require`或`execution::prefer `

1.  方向性：执行函数可以是“触发即忘”(`execution::oneway`)、返回一个future(`execution::twoway`)或返回一个continuation(`execution::then`)。
2.  基数性：执行函数可以创建一个(`execution::single`)或多个执行代理(`execution::bulk`)。
3.  阻塞性：函数可阻塞也可不阻塞，有三个互斥的阻塞属性:`execution::blocking.never`，`execution::blocking.possibly`和`execution::blocking.always`。
4.  持续性：任务可能是由，客户端上的线程执行(`execution::continuation`)，也可能不执行(`execution::not_continuation`)。
5.  可溯性：指定是否跟踪有未完成的工作(`exection::outstanding_work`),或不跟踪(`execution::outstanding_work.untracked`)。
6.  批量进度保证：指定在批量属性，`execution::bulk_sequenced_execution`、`execution::bulk_parallel_execution`和`execution::bulk_unsequenced_execution`，这些属性是互斥的，通过使用这些属性创建的执行代理的保证任务进度。
7.  执行线程映射：将每个执行代理映射到一个新线程(`execution::new_thread_execution_mapping`)，或者不映射(`execution::thread_execution_mapping`)。
8.  分配器：将分配器(`execution::allocator`)与executor关联起来。

你也可以自己来定义属性。

> 知识点
>
> Executor是基础构建块
>
> 因为executor是执行的构建块，C++的并发性和并行性特性在很大程度上依赖于它们。这也适用于扩展的future，网络的[N4734](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4734.pdf)扩展，甚至是适用于STL的并行算法，以及C++20/23中的新并发特性，如锁存和栅栏、协程、事务性内存和任务块。

## 举个栗子

**使用Executor**

下面的代码片段，展示了executor的用法:

**std::async**

```c++
// get an executor through some means
my_executor_type my_executor = ...
  
// launch an async using my executor
auto future = std::async(my_executor, [] {
	std::cout << "Hello world, from a new execution agent!" << std::endl;
});
```

**STL算法std::for_each**

```c++
// get an executor through some means
my_executor_type my_executor = ...
  
// execute a parallel for_each "on" my executor
std::for_each(std::execution::par.on(my_executor),
							 data.begin(), data.end(), func);
```

**网络技术规范：允许客户端连接默认系统Executor**

```c++
// obtain an acceptor (a listening socket) through some means
tcp::acceptor my_acceptor = ...
  
// perform an asynchronous operation to accept a new connection
acceptor.async_accept(
  [](std::error_code ec, tcp::socket new_connection)
    {
    	...
    }
  );
```

**网络技术规范：允许客户端连接带有线程池的Executor**

```c++
// obtain an acceptor (a listening socket) through some means
tcp::acceptor my_acceptor = ...
  
// obtain an executor for a specific thread pool
auto my_thread_pool_executor = ...
  
// perform an asynchronous operation to accept a new connection
acceptor.async_accept(
    std::experimental::net::bind_executor(my_thread_pool_executor,
    [](std::error_code ec, tcp::socket new_connection)
      {
      	...
      }
    )
  );
```

网络技术规范[N4734](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4734.pdf)的`std::experimental::net::bind_executor`函数允许使用特定的executor。本例中，程序在线程池中执行Lambda函数。

要使用executor ，必须进行获取。

**获取Executor**

获取Executor的方法有很多。

**源于自执行上下文static_thread_pool**

```c++
// create a thread pool with 4 threads
static_thread_pool pool(4);

// get an executor from the thread pool
auto exec = pool.executor();

// use the executor on some long-running task
auto task1 = long_running_task(exec);
```

**源自执行策略std:: Execution::par**

```c++
// get par's associated executor
auto par_exec = std::execution::par.executor();

// use the executor on some long-running task
auto task2 = long_running_task(par_exec);
```

**源于系统的Executor **

通常使用线程执行的默认程序。如果有变量没有指定，那就可以使用它。

**源于Executor适配器**

```c++
// get an executor from a thread pool
auto exec = pool.executor();

// wrap the thread pool's executor in a logging_executor
logging_executor<decltype(exec)> logging_exec(exec);

// use the logging executor in a parallel sort
std::sort(std::execution::par.on(logging_exec), my_data.begin(), my_data.end());
```

logging_executo是循环executor的包装器。

## Executor的目标

提案[P1055]( http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1055r0.pdf)中，executor的目的是什么呢?

1. 批量化：权衡可调用单元的转换成本和大小。
2. 异构化：允许可调用单元在异构上下文中运行，并能返回结果。
3. 有序化：可指定调用顺序，可选的顺序：后进先出[LIFO](https://en.wikipedia.org/wiki/Stack_(abstract_data_type))、先进先出[FIFO](https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)) 、优先级或耗时顺序，甚至是顺序执行。
4. 可控化：可调用的对象必须是特定计算资源的目标，可以延迟，也可以取消。
5. 持续化：需要可调用信号来控制异步，这些信号必须指示结果是否可用、是否发生了错误、何时完成可调用或调用方是否希望取消，并且显式启动或停止启动可调用项也应该是可以的。
6. 层级化：层次结构允许在不增加用例复杂性的情况下添加功能。
7. 可用化：易实现和易使用，应该是主要目标。
8. 组合化：允许用户扩展executor的功能。
9. 最小化：executor中不应该存在任何库外添加的内容。

## 术语

The Proposal [P0761](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0761r2.pdf) defines a few new terms for the execution of a callable:

* Execution resource: is an instance of a hardware and/or software capability capable of executing a callable. An execution unit can range from a SIMD vector unit to an entire runtime managing a large collection of threads. Execution resources such as a CPU or a GPU are heterogeneous, because they have different freedoms and restrictions.
* Execution context: is a program object that represents a specific collection of execution resources and the execution agents that exist within those resources. Typical examples are a thread pool or a distributed or a heterogenous runtime.
* Execution agent: is a unit of execution of a specific execution context that is mapped to a single invocation of a callable on an execution resource. Typical examples are a CPU thread or an GPU execution unit.
* Executor: is an object associated with a specific execution context. It provides one or more execution functions for creating execution agents from a callable function object.

## 执行函数

According to the previous paragraph, an executor provides one or more execution function for creating execution agents from a callable. An executor has to support at least one of the six following functions.

The execution functions of an executor





Each execution function has two properties: cardinality and direction.

* Cardinality
  * single : creates one execution agents
  * bulk : creates a group of execution agents
* Direction
  * oneway : creates an execution agent and does not return a result
  * twoway : creates an execution agent and does return a future that can be used to wait for execution to complete
  * then : creates an execution agent and does return a future that can be used to wait for execution to complete. The execution agent begins execution after a given future pred becomes ready.

Let me explain the execution functions more informally.

All of them take a callable.

**Single Cardinality**

The single cardinality is straightforward. A oneway execution function is a fire and forget job and returns void . It’s quite similar to a fire and forget future, but it does not automatically block in the destructor of the future. A twoway execution function returns you a future which you can use to pick up the result. This behaves similarly to a std::promise that give you back the handle to the associated std::future . In the then case it is a kind of continuation. It gives you back a future, but the execution agent runs only if the provided future pred is ready 

**Bulk Cardinality**

The bulk cardinality case is more complicated. These functions create a group of execution agents, and each of these execution agents calls the given callable f .They return the result of a result factory and not the result of a single callable f invoked by the execution agents. The first parameter of f is the shape parameter, which is an integral type and stands for the index of the type of the agent. Further arguments are the result factory if it is a twoway executor and a shape factory, which is shared by all agents. The lifetime of the shared parameter created by the shared factory is bound to the lifetime of the agents. Both are called factories because they produce their value by executing a callable and run before the agents. The client is responsible to disambiguate the right result via this result factory.

When the function bulk_then_execute is used, the callable f takes its predecessor future as an additional argument. The callable f takes the result, the shared parameter, and the predecessor by reference because no agent is an owner.

**execution::require**

How can you be sure that your executor supports the specific execution function?

In the special case, you know it.

Use an oneway single executor

```c++

```

In the general case, you can use the function execution::require to ask for it.

Ask for an twoway_execute single executor

```c++

```

## 实现原型

Based on the proposal [P0443R5]( http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0443r5.html), an protoype implementation of the executor proposal is available. his prototype implementation helped me a lot to get a deeper understanding of the bulk cardinality in particular.

A prototype implementation of the executors

```c++

```

The program uses as executor a thread pool of four threads (lines 14 and 15). The lines 18 and 23 uses execution functions of single cardinality and create two agents of single cardinality. The second one is a twoway execution function and returns, therefore, a result.

The remaining execution functions in lines 30, 39, and 56 are of bulk cardinality. Each function creates eight agents (lines 32, 43, and 60). In the first case, the callable displays the index n and the shared value sha which is created by the shared factory in line 33. The next execution function bulk_twoway_execute is more interesting. Although it’s result factory returns void , the shared state is the atomic variable atom . Each agent increments its value by one (line 42). Thanks to the result factory, the last execution function (lines 56 to 69) returns the result 123.456 . It’s quite interesting to see, how many threads are involved in the execution of the callable and the execution of the result and the shared factory. The output of the program shows that result and shared factory run in the same thread but the agents in a different thread.

![](../../../images/detail/The-Future-CPP-20-23/2.png)